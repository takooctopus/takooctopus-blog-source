---
title: 文献解读（二）：推荐系统算法
date: 2018-10-10 17:19:28
tags: Article
categories: Article # 分类
thumbnail: /assets/img/posts/Article/default.jpg
---

>本文由[本人@takooctopus](https://takooctopus.github.io "たこ焼きのGITHUB")看文献时的感想，并在此附上原文地址
>[Deep Learning based Recommender System: A Survey and New Perspectives](http://de.arxiv.org/pdf/1707.07435v5 "Deep Learning based Recommender System: A Survey and New Perspectives")
>由于翻译实在太过于耗费时间，有些地方可能我会加以省略或者以自己理解进行阐述

# 推荐系统(RS)简述

现在个人信息量爆炸，推荐系统可以有效的过滤并向人推荐其所喜欢的东西。

其一般被分作三类：

- collaborative filtering 协同过滤

- content-based recommender system 基于内容的推荐系统

- hybrid recommender system based on the types of input data 基于输入数据的混合的推荐系统[^1]


但其都有各自的问题，譬如稀疏性、冷启动，以及其不同评价指标下的推荐性能 [^1] [^6] [^74] [^110]


## 关于深度学习在RS中的运用

公司案例

- Netflix [^31]
- Youtube [^20] [^17]
- Google Play [^12]
- Yahoo News [^81]

研究领域内

- RecSys


## 以前与现在的区别

以前成果

-   一个协同过滤技术的评价系统 [^100]
-   混合推荐系统 [^6]
-   跨域推荐模型[^27] [^50]
-   三种评价模型 [^89] [^109] [^113] 的简单介绍 [^5]
-   对13篇文章的回顾 [^68]


# 术语以及背景概念

我们称推荐系统的定义：用于评价用户对于他们没有见过的物品的喜欢倾向程度。

一般三个主要输出的评价因素：`评价预测`，`排名预测`以及`分类`

我们将其需要的主要符号放出来

|   Notation    |   Description |   Notation    |   Description |
|   :------     |   :------     |   :------     |   :------     |
|   $ R $       |   评价矩阵     |   $ \hat{R} $ |   预测评价矩阵    |
|   $ M $       |   用户数       |   $ N $       |   物品总数    |
|   $ r_{ui}$   |   用户`u`对物品`i`的评价  |   $ \hat{r}_{ui} $    |   用户`u`对`i`的预测评价  |
|   $ r^{i} $   |   物品`i`的部分观察向量   |   $ r^{u} $   |   用户`u`的部分观察向量   |
|   $ U $       |   用户潜在因素    |   $ V $       |   物品潜在因素    |
|   $ k $       |   潜在因素的大小  |   $ K $       |   评价的最大值(明确的)    |
|   $ \mathcal{O} , \mathcal{O}^{-} $ |   已观测，未观测的评价集合  |   $ I $       |   指示符「如果 $ r_{ui} != 0 $ ，$ I_{ui} = 1$；反之为 $ I_{ui} = 0$ 」    |
|   $ W_* $     |   神经网络的权重矩阵  |   $ b_{*} $   |   神经网络的偏置  |

基于内容的推荐系统依赖了物品与用户的辅助信息

而混合式的推荐系统有两到三种推荐策略 [^6]

## 深度学习技术

深度学习作为机器学习的一个子类，能够解决监督学习和非监督学习的问题[^21]。

- • Multilayer Perceptron (MLP) 多层感知
- • Autoencoder (AE) 自动编码技术[^11] [^33]
    + denoising autoencoder
    + marginalized denoising autoencoder
    + sparse autoencoder
    + contractive autoencoder
    + variational autoencoder
- • Convolutional Neural Network (CNN) [^33] 卷积神经网络
- • Recurrent Neural Network (RNN) [^33] 循环神经网络
    + Long Short Term Memory (LSTM)
    + Gated Recurrent Unit (GRU) network
- • Deep Semantic Similarity Model (DSSM) 「Deep Structured Semantic Model」深层语义模型
- • Restricted Boltzmann Machine (RBM) 受限波尔兹面向量机
- • Neural Autoregressive Distribution Estimation (NADE) 神经自回归分布估计 [^57] [^108]
- • Generative Adversarial Network (GAN) 生成对抗网络[^34]


# 分类方案和分析

## 二维分类方案
|       |   Recommend Rely Solely   |   Tightly Coupled Model | Loosely Coupled Model   |
| :-------    |   :------ |   :------ |   :------ |
|   MLP(15)   |  [46], [133], [2], [111] ,[118], [38], [9], [25] [12]    |  [10], [65], [17], [35], [39] | [66] |
|   AE(25)  |   [82], [90], [99], [129], [98], [135], [144], [102], [84]    |   [113], [63], [62], [24], [112] , [145], [3], [136]   |   [139],[122], [123], [106], [7], [146], [107], [22] |
|   CNN(17) |   [32], [79], [120]   |   [51], [52], [140], [109], [91], [69]  |   [15], [93], [143], [73], [36], [37], [124]. [117]    |
|   RNN (22)    |   [4], [53], [94], [18], [64], [104], [126], [49], [41], [128], [127], [40], [101], [103], [77], [130], [125], [23]   |   [19], [105], [81]   |   [96]    |
|   DSSM (3)    |  [26], [8], [132]  |   *  |   *   |
|   RBM (7)     |   [89], [30], [70], [131], [47]    |  *   |   [48], [119] |
|   NADE (2)    |   [142], [141]    |   *   |   *   |
|   GAN (1)     |   *   |   [116]   |   *   |
|   /   |   |   |   |
|   Deep Composite Model (10)   |   [59], [85], [138], [97], [25], [61], [58], [28]  |   [137], [114]   |   *   |


- 神经网络模型
    + 简单深度学习技术模型
        * MLP 能简单的对于用户和物品的互动的非线性关系建模
        * AE 
        * CNN 能从文本或图像信息的异构数据中提取本地或全局表示
        * RNN 能对评级数据进行动态建模，也能对内容信息进行连续建模
        * DSSM 能进行语义匹配
        * RBM
        * NADE
        * GAN
- 综合深度学习模型
    + 深度学习与传统推荐相结合
    + 自主推荐深度学习


## 定性分析

- 我们看见最近几年中AE, RNN, CNN and MLP应用广泛，然后是 deep composite models, RBM and DSSM based models
- 关于数据集： Movielens Neflix Amazon Yelp CiteUlike


## 应用领域

- Image [^59] [^124] [^130]
- Music [^49] [^109] [^66] [^119]
- POI [^117] [^133] [^106] [^107]
- News [^8] [^120] [^81] [^97]
- HashTag [^85] [^138] [^32] [^112]
- Quote [^58] [^103]
- Ciation [^25] [^46]

# 基于深度学习的推荐系统

## 基于独立深度学习的推荐

### Neural Collaborative Filtering (NCF) 神经协同过滤

我们设定$ s_{u}^{user} $ 和 $ s_{i}^{item} $ 为单边信息

且我们NCF的预测公式定义为：

\begin{align}
    \hat{r}_{ui} = f( U^{T} \cdot s\_{u}^{user} , V^{T} \cdot  s\_{i}^{item} | U, V, \Theta) 
\end{align}

其中 $ f( \cdot ) $ 是多层感知器，$ \Theta $ 是网络参数

我们定义损失函数「我们使用加权方差表示」：

\begin{align}
    \mathcal{L} = \sum_{(u,i) \in \mathcal{O} \cup \mathcal{O}^{-}} w_{ui} (r_{ui} - \hat{r}_{ui})^2 
\end{align}

我们 $ w_{ui} $ 是需要的权重

比方说我们我们使用二进制「`0`代表dislike，`1`代表like」，则我们约束输出 $ \hat{r}_{ui} $ 到 `[0,1]` 之中，重新定义损失函数 $ \mathcal{L} $

\begin{align}
    \mathcal{L} = - \sum_{(u,i) \in \mathcal{O} \cup \mathcal{O}^{-}}  r_{ui} log \hat{r}_{ui} + (1-r\_{ui}) log (1-\hat{r}\_{ui})
\end{align}

因为有大量的未观测实例，NCF采用了大量的负采样去减少训练集的大小，极大的提高了学习效率。

- [^118] 中拓展了 NCF 模型到了跨域推荐模型
- [^65] 中拓展为 CCCFNet 「(Cross-domain Content-boosted Collaborative Filtering neural Network」 

### 广度 & 深度 学习

同时解决回归和分类问题，最开始应用于Google Play [^12]

其中广度学习组件是单层的，而深度学习组件的视图是多层的

整个网络的记忆功能由广度学习组件实现，而深度组件实现其生成的功能

一般的，我们定义广度组件

\begin{align}
    y = W^{T}_{wide} \lbrace x , \phi (x) \rbrace + b
\end{align}

而深层组件的每一层我们都定义其形式

\begin{align}
    {\alpha}^{l+1} = f(W^{T}_{deep} a^{(l)} + b^{(l)})
\end{align}

$ f (\cdot) $ 是激活函数

整个模型就是他们的结合

\begin{align}
    P(\hat{r}_{ui} = 1 | x) = \sigma ( W^{T}\_{wide} \lbrace x , \phi (x) \rbrace + W^{T}\_{deep} a^{(l_f)} + bias )
\end{align}

其中 $ \sigma (\cdot)$ 是sigmoid函数， $ a^{(l_f)} $ 是最后激活

这个模型的拓展

- [^9] 本地连接的广度&深度学习模型


### Deep Factorization Machine 深度分解机 [^35]

- 端到端模型
- 高层特性via深层神经网络
- 低级特性通过分解机

其输入为`m-field`数据包括了`(u,i)`

而其输出被定义为 $ y_{FM}(x) $ 以及 $ y_{MLP} (x) $

最终预测的分数被记作：

\begin{align}
    \hat{r}_{ui} = \sigma ( y\_{FM}(x) + y\_{MLP}(x) )
\end{align}


## MLP与传统推荐系统集成 

### 关注型协同过滤

- 语音识别 [^13]
- 机器翻译 [^72]
- 最近应用于机器学习上的成就 [^10] [^32] [^91]
- 基于 MLP 的 化妆品推荐 [^2]
- MLP 的  Youtube 推荐

## 基于自编码的推荐系统

### 全基于自编码系统 [^90]

在用户以及物品的向量 $ r^{(u)} $ 和 $ r^{(i)} $ 作为输入，结合两者，有基于用户以及基于物品的两条重构线：

现在仅以物品线为例：

\begin{align}
    h( r^{(i)} ; \theta ) = f(W \cdot g( V \cdot r^{(i)} + \mu ) + b)
\end{align}

即物品线的目标函数：

\begin{align}
	\mathop{\arg\min}_{\mathbf{\theta}} \sum^{N}\_{i=i} || r^{(i)} - h( r^{(i)} ; \theta ) ||^{2}\_{\mathcal{O}} + \lambda \cdot Regularization
\end{align}

其中 $ || \cdot || $ 表示其只包含已经观察到的评级

注意： 

- 物品线比用户线的性能更好「可能是因为用户观察到的方差更高」
- `f()`和`g()`对性能有所影响
- 隐藏层单元数的增加会提高解释度
- 增加层数会提高性能


### Collaborative Filtering Neural network (CFN) 协同过滤神经网络 [^98] [^99]

- 是AutoRec的拓展
- 鲁棒性更高
- 稀疏性和冷启动的影响降低

三种输入的噪声：

- 高斯噪声
- 掩蔽噪声
- 椒盐噪声

但我们现在使用 $ \tilde{r}^{(i)} $ 即腐化的输入作为输入

我们定义损失函数

\begin{align}
    \mathcal{L} = \alpha ( \sum_{i \in I(\mathcal{O}) \cap I(\mathcal{C}) } \[ h(\tilde{r}^{(i)}) - r^{(i)} \]^2 )  +  \beta ( \sum_{i \in I(\mathcal{O}) / I(\mathcal{C}) } \[ h(\tilde{r}^{(i)}) - r^{(i)} \]^2 )  +  \lambda \cdot Regularization
\end{align}

其中 $ I(\mathcal{O}) $ 与 $ I(\mathcal{C}) $ 都是观测到的腐化元素的指标， $ \alpha $ 和 $ \beta $ 是平衡两种影响的超参数

CFN的一种`改进`会包含辅助信息，但是是将其注入到了所有层中：

我们的重建函数`h()`会变为

\begin{align}
    h({\tilde{r}^{(i)}, s_i }) = f (W_2 \cdot \lbrace g(W_1 \cdot {r^{(i)}, s_i \} + \mu ), s_i \rbrace + b)
\end{align}

### Autoencoder-based Collaborative Filtering (ACF) 自编码协同过滤 [^82]

他们会将全输入数据按情况分为`K`组「range」，每个 $ r^{i} $ 都会被分成`K`个单独的向量

虽然其使用了RBM技术去跟踪参数避免局部最优，但仍旧有两个问题：

- 无法处理非整数问题
- 观测的分解导致了输入数据的稀疏性


### Collaborative Denoising Auto-Encoder (CDAE) 协同去噪自编码 [^129]

其输入是观察到的用户输入的隐式反馈 $ r^{(u)}_{pref} $ ，同样的，采用`0`和`1`代表喜不喜欢。

腐化输入 $ \tilde{r}^{(u)}\_{pref} $ 由条件高斯分布 $ p( \tilde{r}^{(u)}\_{pref} | r^{(u)}\_{pref} )$  而来

我们就可以定义重建函数：

\begin{align}
    p( \tilde{r}^{(u)}\_{pref} ) = f(W_2 \cdot g(W_1 \cdot \tilde{r}^{(u)}\_{pref} + V_u + b_1 ) + b_2)
\end{align}

这时我们只需要最小化重建误差就行了：

\begin{align}
    \mathop{\arg\min}_{\mathbf{ W_1, W_2, V, b_1, b_2}} \frac{1}{M}  \sum^{M}\_{u=1} E\_{p( \tilde{r}^{(u)}\_{pref} | r^{(u)}\_{pref} )} \[  l (\tilde{r}^{(u)}\_{pref}, h(\tilde{r}^{(u)}\_{pref}) ) \] + \lambda \cdot Regularization
\end{align}

在 $ l( \cdot ) $ 可以是方差 或者 logistic 误差，其遵照 $l_2$ 范数 而不是 [弗罗贝尼乌斯范数](https://zh.wikipedia.org/wiki/%E7%9F%A9%E9%99%A3%E7%AF%84%E6%95%B8)去标准化其权重和偏置

### 紧耦合模型与松耦合模型


#### 紧耦合模型 Tightly Coupled Model 

- 需要仔细设计和优化以避免局部最优
- 推荐和功能学习可以立即进行

***

##### Collaborative Deep Learning (CDL) 协同深度学习 [^113]

- 分层贝叶斯模型 [^115]
    + 观测组件 「深层神经网络」 ----SDAE
    + 特殊任务组件  ----PMF
   
***

##### Collaborative Deep Ranking (CDR) 协同深度排名 [^136]

- 成对模型更加适合排名列表生成 [^87] [^129] [^136]

***

##### Deep Collaborative Filtering Framework 深层协作过滤框架 [^62]


***


#### 松耦合模型 Loosely Coupled Model

- 容易拓展
- 需要更多的训练步骤

***

##### AutoSVD [^139]

利用收缩自动编码器 [^88]，并集成到经典推荐模型 SVD++ [^54]中

- 与其他自动编码器变体相比，收缩自动编码器捕获了几个自动编码器输入变化 
- 对隐式反馈进行建模，以进一步提高准确性; 
- 有效的训练算法旨在减少训练时间

***

##### HRCD [^122] [^123]

基于自动编码器和timeSVD++ [^55] 的混合协作模型

冷项目上的代价比较高

***


## 基于卷积神经网络的推荐系统

### 完全基于CNN的推荐系统

#### Attention based CNN

将hashtag视作`多类型`的分类问题

主题上分为了全局通道和本地注意通道

- 全局通道 「所有的word都在全局通道的输入中被编码」
    + convolution lters 卷积滤波器
    + max-pooling layers 最大池化层
- 本地注意通道
    + 一个注意层「窗口大小 $ h $ 并且阈值 $ \eta $ 」用以选择信息词「这里称`trigger word`」

我们设 $ w_{i:i+h} $ 为 $ w_i, w_{i+1}, ..., w_{i+h} $ 词的级联 

对于中位词 $ w_{(2i+h-1)/2} $ 的分数为：

\begin{align}
    s_{(2i+h-1)/2} = g( W \cdot w_{i:i+h} +b )
\end{align}

同样的 $ W $仍旧是矩阵的权， 而 $ g(\cdot) $ 为一个非线性的激活函数

我们仅仅保存分数高于 $ \eta $ 的词


##### 后续的进步:

- [^91] 中做了一个和 [^32] 相似的使用了两层神经网络进行预测
- [^79] 是一个特征CNN标签推荐「Personalized CNN Tag Recommendation」，其优化使用了 贝叶斯特征评价算法「Bayesian Personalized Ranking (BPR) algorithm」 [^87]

***

传统推荐系统与CNN的集成 Integrate CNN with Traditional Recommender System

同样的，这里面也有紧耦合和松耦合的区别

### 紧耦合和松耦合

#### 紧耦合模型 Tightly Coupled Model

##### 深层协作神经网络 Deep Cooperative Neural Network (DeepCoNN) [^144]

采用两个并行卷积神经网络来模拟评论文本中的用户行为和项目属性。 在最终层中，分解机器用于捕获它们的相互作用以进行评级预测。 它减轻了稀疏性问题并增强了解释性。

使用了单词嵌入技术，将评论文本映射到低维语义空间

最后用户网络和物品网络的输出 $ x_u $ 和 $ x_i $ 会作为分解机的输入

****
`ConvMF` 在 [^51] 中结合了CNN 和 PMF， 其方式像协同深度学习 CDL。  

当然，这种将`ConvMF`这种基于CDL的好处在于 CNN能够通过词语的注入和卷积内核准确的捕捉上下文信息

我们仅仅需要把 CDL 中的 $ X^{T}_{\frac{L}{2}, i*} $ 替换掉，使用 CNN 中的 $ cnn(W, X_i) $ 来代替，定义损失函数如下：

\begin{align}
    \mathcal{L} = \sum^{N}\_{i} \sum^{M}\_{u} \frac{I_{ui}}{2} (R_{ui} - U^T_u V_i)^2 + \frac{\lambda_{u}}{2} \sum^{M}\_{u} || U_{u} || + \frac{\lambda_{v}}{2} \sum^{N}\_{i} || V_i - cnn(W, X_i) || + \lambda_W \cdot Regularization
\end{align}

其中 $ \lambda $ 都是超参数， 而 $ U $ 和 $ V $ 都从协调下降中学到，即我们通过修复 $ U $ 和 $ V $ 时修复CNN的参数

***

#### 松耦合模型 Lossely Coupled Model

三种类型

##### CNN for Image Feature Extraction

[^117] 中提及一种 兴趣点「Point-of-Interest」(POI) 的技术，并将其提炼为了POI recommender system (VPOI) 

其仍旧是基于CNN的，建立于PMF上，寻找下面的内部联系：

- 视觉内容和建在用户因素
- 视觉内容和潜在位置因素

[^15] 中提及了餐馆里的应用

[^37] 可视贝叶斯特征排名算法 「visual Bayesian personalized ranking」 (VBPR)

***

##### CNN for Audio Feature Extraction

[^109] 音乐信号中提取特征

卷积核和池化层允许多时间段的操作

能解决音乐推荐的冷启动问题

如果以 $ y $ 和 $ y' $ 定义 从加权矩阵分解中学习到的潜在因素值 和 最终 CNN 的输出值，我们的目标就是要最小化 $ y $ 和 $ y' $ 之间的方差

***

##### CNN for Text Feature Extraction

[^93] e-learning resources recommendation model

使用CNN去从文本信息中解读特征

同时还有 [^109]

***


## 基于递归神经网络的推荐系统 Recurrent Neural Network based Recommender System (RNN)

这个适合于评分的时间动态以及推荐系统的序列特征

### 完全基于RNN的推荐系统

